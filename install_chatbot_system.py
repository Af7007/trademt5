#!/usr/bin/env python3
"""
Sistema de Instala√ß√£o do Chatbot IA para Trading
Instala e configura: Ollama + OpenWebUI + Integra√ß√£o com Motor de Predi√ß√£o
"""

import subprocess
import sys
import os
import time
import requests
import json
from pathlib import Path

class TradingChatbotInstaller:
    def __init__(self):
        self.base_dir = Path(__file__).parent
        self.ollama_url = "http://localhost:11434"
        self.openwebui_port = 8080
        self.openwebui_url = f"http://localhost:{self.openwebui_port}"

        # Configura√ß√µes dos modelos
        self.models_to_install = [
            "mistral",  # Modelo mais r√°pida e eficiente
            "llama2:7b"  # Alternativa se mistral falhar
        ]

    def run_command(self, cmd, description="Executando comando", shell=False):
        """Executa comando do sistema com feedback"""
        print(f"[EXEC] {description}...")
        print(f"CMD: {cmd}")

        try:
            if shell:
                result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
            else:
                result = subprocess.run(cmd.split(), capture_output=True, text=True)

            if result.returncode == 0:
                print(f"[OK] {description}")
                if result.stdout:
                    print(f"Output: {result.stdout.strip()}")
                return True
            else:
                print(f"[FAIL] {description}")
                if result.stderr:
                    print(f"Error: {result.stderr.strip()}")
                return False

        except Exception as e:
            print(f"[ERROR] {description}: {str(e)}")
            return False

    def check_python_dependencies(self):
        """Verifica e instala depend√™ncias Python necess√°rias"""
        required_packages = [
            "requests",
            "flask",
            "flask-cors"
        ]

        print("Checking Python dependencies...")

        for package in required_packages:
            try:
                __import__(package.replace("-", "_"))
                print(f"[OK] {package}")
            except ImportError:
                print(f"Installing {package}...")
                if not self.run_command(f"pip install {package}", f"Installing {package}"):
                    print(f"[FAIL] Could not install {package}")
                    return False

        return True

    def install_ollama(self):
        """Instala o Ollama"""
        print("Installing Ollama...")

        # Para Windows, baixa o installer
        if sys.platform == "win32":
            print("Windows platform detected")

            # Tenta instalar via curl
            if self.run_command("where curl", "Checking curl", shell=True):
                print("Downloading Ollama via curl...")
                ollama_install = 'curl -fsSL https://ollama.com/install.bat | powershell'
                return self.run_command(ollama_install, "Installing Ollama", shell=True)
            else:
                print("[FAIL] Ollama needs manual installation from: https://ollama.com/download")
                print("Run this script again after installation")
                return False
        else:
            print("Linux/Mac platform - installing via official script")
            # Para Linux/Mac
            return self.run_command('curl -fsSL https://ollama.com/install.sh | sh',
                                   "Installing Ollama on Linux/Mac", shell=True)

    def start_ollama_service(self):
        """Inicia o servi√ßo Ollama"""
        print("Starting Ollama service...")

        # Tenta iniciar Ollama
        if sys.platform == "win32":
            # No Windows, precisa executar ollama serve
            try:
                # Tenta executar em background usando subprocess
                subprocess.Popen(["ollama", "serve"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
                time.sleep(3)  # Aguarda inicializa√ß√£o
                print("[OK] Ollama started (background)")
                return True
            except:
                print("[FAIL] Could not start Ollama automatically")
                print("Run manually: ollama serve")
                return False
        else:
            # Linux/Mac pode usar systemctl ou iniciar diretamente
            return self.run_command("ollama serve", "Starting Ollama (will run in background)", shell=True)

    def pull_models(self):
        """Baixa modelos necess√°rios"""
        print("Downloading AI models...")

        success = False
        for model in self.models_to_install:
            print(f"Downloading model: {model}")

            if self.run_command(f"ollama pull {model}", f"Downloading {model}"):
                success = True
                break  # Usa o primeiro modelo que conseguir baixar
            else:
                print(f"Warning: Failed to download {model}, trying next...")

        if not success:
            print("[FAIL] Could not download any models")
            print("Run manually: ollama pull mistral")
            return False

        return True

    def install_openwebui(self):
        """Instala o OpenWebUI"""
        print("Installing OpenWebUI...")

        try:
            # Instala via pip
            if self.run_command("pip install open-webui", "Installing OpenWebUI"):
                print("[OK] OpenWebUI installed via pip")

                # Cria script de inicializa√ß√£o
                startup_script = '''#!/bin/bash
# Script para iniciar OpenWebUI
echo "Iniciando OpenWebUI..."
open-webui serve --host 0.0.0.0 --port 8080
'''

                with open("start_openwebui.sh", "w") as f:
                    f.write(startup_script)

                # Tamb√©m cria script Windows
                startup_bat = '''@echo off
echo Iniciando OpenWebUI...
open-webui serve --host 0.0.0.0 --port 8080
pause
'''

                with open("start_openwebui.bat", "w") as f:
                    f.write(startup_bat)

                print("üìú Scripts de inicializa√ß√£o criados:")
                print("üêß Linux/Mac: ./start_openwebui.sh")
                print("ü™ü Windows: start_openwebui.bat")

                return True
            else:
                return False

        except Exception as e:
            print(f"‚ùå Erro ao instalar OpenWebUI: {e}")
            return False

    def test_ollama_connection(self):
        """Testa conex√£o com Ollama"""
        print("üîó Testando conex√£o com Ollama...")

        try:
            response = requests.get(f"{self.ollama_url}/api/tags", timeout=5)
            if response.status_code == 200:
                models = response.json()
                print(f"‚úÖ Ollama conectado - Modelos dispon√≠veis: {len(models.get('models', []))}")

                for model in models.get('models', []):
                    print(f"  üì¶ {model.get('name', 'Unknown')}")
                return True
            else:
                print(f"‚ùå Ollama respondeu com c√≥digo {response.status_code}")
                return False

        except requests.exceptions.ConnectionError:
            print("‚ùå N√£o foi poss√≠vel conectar ao Ollama")
            print("üí° Certifique-se que o Ollama est√° rodando: ollama serve")
            return False
        except Exception as e:
            print(f"‚ùå Erro ao testar Ollama: {e}")
            return False

    def create_trading_chatbot_api(self):
        """Cria API de integra√ß√£o com o chatbot IA"""
        print("ü§ñ Criando API de integra√ß√£o do chatbot com motor de predi√ß√£o...")

        # C√≥digo da API de integra√ß√£o
        chatbot_api_code = '''#!/usr/bin/env python3
"""
API de Integra√ß√£o: Chatbot IA com Motor de Predi√ß√£o de Trading
Permite ao OpenWebUI fazer perguntas sobre o motor de predi√ß√£o
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from flask import Flask, request, jsonify
from flask_cors import CORS
import requests
import json
import logging
from datetime import datetime

# Import motor de predi√ß√£o
try:
    from prediction_engine import PredictionEngine
    from models import PredictionRequest
except ImportError as e:
    print(f"Erro ao importar motor de predi√ß√£o: {e}")
    PredictionEngine = None

# Configura√ß√£o logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

app = Flask(__name__)
CORS(app)  # Permite requisi√ß√µes do OpenWebUI

# URLs
OLLAMA_URL = "http://localhost:11434"
PREDICTION_API_URL = "http://localhost:5000"  # Motor de predi√ß√£o existente

class TradingChatbotAssistant:
    """Assistente de trading que conecta IA com dados de predi√ß√£o"""

    def __init__(self):
        self.prediction_engine = None
        if PredictionEngine:
            try:
                self.prediction_engine = PredictionEngine()
                logger.info("Motor de predi√ß√£o conectado")
            except Exception as e:
                logger.error(f"Erro ao conectar motor de predi√ß√£o: {e}")

    def query_ollama(self, prompt, model="mistral"):
        """Consulta modelo Ollama"""
        try:
            response = requests.post(
                f"{OLLAMA_URL}/api/generate",
                json={
                    "model": model,
                    "prompt": prompt,
                    "stream": False
                },
                timeout=30
            )

            if response.status_code == 200:
                return response.json()["response"]
            else:
                return f"Erro na API Ollama: {response.status_code}"

        except Exception as e:
            return f"Erro ao consultar Ollama: {str(e)}"

    def get_prediction_analysis(self, symbol, target_profit=None, balance=1000):
        """Obt√©m an√°lise de predi√ß√£o atual"""
        try:
            if not self.prediction_engine:
                return "Motor de predi√ß√£o n√£o dispon√≠vel"

            # Cria requisi√ß√£o
            request_data = PredictionRequest(
                symbol=symbol.upper(),
                target_profit=float(target_profit or 50.0),
                balance=float(balance)
            )

            # Gera predi√ß√£o
            result = self.prediction_engine.predict(request_data)

            return {
                "estimated_operations": result.estimated_operations,
                "estimated_duration": result.estimated_duration_description,
                "success_probability": round(result.success_probability * 100, 1),
                "risk_level": result.risk_level,
                "backtest_results": result.backtest_results.to_dict() if result.backtest_results else "Dados hist√≥ricos n√£o dispon√≠veis"
            }

        except Exception as e:
            logger.error(f"Erro na an√°lise de predi√ß√£o: {e}")
            return f"Erro ao obter dados de predi√ß√£o: {str(e)}"

    def process_trading_question(self, question, model="mistral"):
        """Processa pergunta sobre trading e gera resposta"""

        # Identifica tipo de pergunta
        question_lower = question.lower()

        # Reuni√£o de contextos baseada na pergunta
        context_parts = []

        # Sempre incluir dados atuais se perguntar sobre mercado ou predi√ß√µes
        if any(keyword in question_lower for keyword in ["mercado", "pre√ßo", "an√°lise", "predi√ß√£o", "entr", "rsi", "macd"]):
            # Extrair s√≠mbolos mencionados
            symbols_mentioned = []
            for symbol in ["xauusd", "btcusd", "eurusd", "gbpusd", "usdjpy"]:
                if symbol.lower() in question_lower:
                    symbols_mentioned.append(symbol.upper())

            if symbols_mentioned:
                context_parts.append(f"Dados atuais do mercado para: {', '.join(symbols_mentioned)}")
                for symbol in symbols_mentioned:
                    prediction_data = self.get_prediction_analysis(symbol)
                    if isinstance(prediction_data, dict):
                        context_parts.append(f"""
{symbol}:
- Opera√ß√µes estimadas: {prediction_data['estimated_operations']}
- Tempo estimado: {prediction_data['estimated_duration']}
- Probabilidade de sucesso: {prediction_data['success_probability']}%
- N√≠vel de risco: {prediction_data['risk_level']}
                        """.strip())

        # Prompt inteligente para Ollama baseado no contexto
        system_prompt = """Voc√™ √© um assistente especialista em trading que combina an√°lise t√©cnica e dados reais.

REGRAS IMPORTANTES:
- Seja preciso e conservador nas recomenda√ß√µes
- Sempre mencione que a an√°lise √© educacional
- Use dados fornecidos na pergunta
- Recomende sempre gerenciamento de risco
- N√£o promova trading irrespons√°vel

RESPONDA EM PORTUGU√äS BRASILEIRO.
"""

        context_text = "CONTEXTO ATUAL:\\n" + "\\n".join(context_parts) if context_parts else "Sem dados espec√≠ficos dispon√≠veis no momento."

        full_prompt = f"{system_prompt}\\n\\n{context_text}\\n\\nPERGUNTA: {question}\\n\\nRESPOSTA:"

        # Consulta IA
        logger.info(f"Consultando IA sobre: {question[:50]}...")
        response = self.query_ollama(full_prompt, model)

        return response

# Inst√¢ncia global
trading_assistant = TradingChatbotAssistant()

@app.route("/health")
def health_check():
    """Health check da API"""
    return jsonify({
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "services": {
            "ollama": test_ollama_connection(),
            "prediction_engine": trading_assistant.prediction_engine is not None
        }
    })

@app.route("/chat", methods=["POST"])
def chat_endpoint():
    """Endpoint principal para conversa√ß√£o com chatbot"""
    try:
        data = request.json
        if not data or 'message' not in data:
            return jsonify({
                "error": "Campo 'message' obrigat√≥rio",
                "example": {"message": "Qual a probabilidade para XAUUSD?", "model": "mistral"}
            }), 400

        question = data['message']
        model = data.get('model', 'mistral')

        logger.info(f"Nova pergunta: {question[:100]}...")

        # Processa pergunta
        response = trading_assistant.process_trading_question(question, model)

        return jsonify({
            "response": response,
            "timestamp": datetime.now().isoformat(),
            "model_used": model
        })

    except Exception as e:
        logger.error(f"Erro no chat endpoint: {e}")
        return jsonify({
            "error": f"Erro interno: {str(e)}",
            "timestamp": datetime.now().isoformat()
        }), 500

def test_ollama_connection():
    """Testa conex√£o com Ollama"""
    try:
        response = requests.get(f"{OLLAMA_URL}/api/tags", timeout=5)
        return response.status_code == 200
    except:
        return False

def main():
    print("ü§ñ Iniciando Trading Chatbot Assistant API...")
    print("üì° Endpoints:")
    print("  GET  /health  - Health check")
    print("  POST /chat    - Conversar com assistente (body: {'message': '...', 'model': 'mistral'})")
    print("üöÄ Servindo em http://localhost:5001")

    app.run(host='0.0.0.0', port=5001, debug=False)

if __name__ == "__main__":
    main()
'''

        # Salva arquivo API
        api_file = self.base_dir / "trading_chatbot_api.py"
        with open(api_file, "w", encoding="utf-8") as f:
            f.write(chatbot_api_code)

        print(f"üìÅ API criada: {api_file}")
        print("üîó Endpoint do chatbot: http://localhost:5001")

        return True

    def test_integration(self):
        """Testa integra√ß√µes ap√≥s instala√ß√£o"""
        print("üß™ Testando integra√ß√µes...")

        # Testa API do chatbot
        try:
            response = requests.get("http://localhost:5001/health", timeout=5)
            if response.status_code == 200:
                data = response.json()
                print("‚úÖ API do chatbot funcionando")
                print(f"   Ollama: {'‚úÖ' if data['services']['ollama'] else '‚ùå'}")
                print(f"   Motor de predi√ß√£o: {'‚úÖ' if data['services']['prediction_engine'] else '‚ùå'}")

                # Testa chat
                test_question = "Qual a probabilidade de sucesso para XAUUSD?"
                chat_response = requests.post("http://localhost:5001/chat",
                    json={"message": test_question}, timeout=30)

                if chat_response.status_code == 200:
                    print("‚úÖ Chatbot funcionando")
                    print(f"   Resposta de teste: {chat_response.json()['response'][:100]}...")
                else:
                    print("‚ö†Ô∏è Chatbot iniciou mas sem resposta")

                return True
            else:
                print("‚ùå API do chatbot n√£o responde")
                return False

        except Exception as e:
            print(f"‚ùå Erro ao testar integra√ß√µes: {e}")
            return False

    def create_startup_scripts(self):
        """Cria scripts de inicializa√ß√£o do sistema completo"""
        print("üìú Criando scripts de inicializa√ß√£o...")

        # Script principal para iniciar tudo
        main_startup = '''#!/bin/bash
# Script completo para iniciar: Ollama + OpenWebUI + Trading Chatbot API
echo "=========================================="
echo "ü§ñ SISTEMA TRADING CHATBOT - INICIALIZANDO"
echo "=========================================="

echo ""
echo "1Ô∏è‚É£ Iniciando Ollama..."
# Verifica se Ollama j√° est√° rodando
if curl -s http://localhost:11434/api/tags > /dev/null; then
    echo "‚úÖ Ollama j√° est√° rodando"
else
    echo "üöÄ Iniciando Ollama..."
    nohup ollama serve > ollama.log 2>&1 &
    sleep 3
fi

echo ""
echo "2Ô∏è‚É£ Iniciando Trading Chatbot API..."
# Verifica se API j√° est√° rodando
if curl -s http://localhost:5001/health > /dev/null; then
    echo "‚úÖ Trading Chatbot API j√° est√° rodando"
else
    echo "üöÄ Iniciando Trading Chatbot API..."
    nohup python trading_chatbot_api.py > chatbot.log 2>&1 &
    sleep 2
fi

echo ""
echo "3Ô∏è‚É£ Iniciando OpenWebUI..."
# Verifica se OpenWebUI j√° est√° rodando
if curl -s http://localhost:8080 > /dev/null; then
    echo "‚úÖ OpenWebUI j√° est√° rodando"
else
    echo "üöÄ Iniciando OpenWebUI..."
    nohup open-webui serve --host 0.0.0.0 --port 8080 > openwebui.log 2>&1 &
    sleep 3
fi

echo ""
echo "4Ô∏è‚É£ Verificando status dos servi√ßos..."
echo "üîó Ollama: http://localhost:11434"
echo "üîó Trading Chatbot API: http://localhost:5001"
echo "üîó OpenWebUI: http://localhost:8080"
echo "üîó Motor de Predi√ß√£o: http://localhost:5000"

echo ""
echo "üß™ Testando conex√µes..."
if curl -s http://localhost:11434/api/tags > /dev/null; then
    echo "‚úÖ Ollama OK"
else
    echo "‚ùå Ollama FALHA"
fi

if curl -s http://localhost:5001/health > /dev/null; then
    echo "‚úÖ Chatbot API OK"
else
    echo "‚ùå Chatbot API FALHA"
fi

if curl -s http://localhost:8080 > /dev/null; then
    echo "‚úÖ OpenWebUI OK"
else
    echo "‚ùå OpenWebUI FALHA"
fi

echo ""
echo "üéâ SISTEMA PRONTO!"
echo "üì± Acesse o chatbot em: http://localhost:8080"
echo "üìä Dashboard de predi√ß√£o em: http://localhost:5000/prediction/dashboard"
echo ""
echo "üí° Digite: 'Me ajude com an√°lise de trading no XAUUSD'"
echo "=========================================="
'''

        with open("start_trading_chatbot.sh", "w") as f:
            f.write(main_startup)

        # Vers√£o Windows
        startup_bat = '''@echo off
echo ==========================================
echo ü§ñ SISTEMA TRADING CHATBOT - INICIALIZANDO
echo ==========================================
echo.

echo 1Ô∏è‚É£ Verificando Ollama...
curl -s http://localhost:11434/api/tags >nul 2>&1
if %errorlevel% equ 0 (
    echo ‚úÖ Ollama j√° est√° rodando
) else (
    echo üöÄ Iniciando Ollama...
    start /B ollama serve > ollama.log 2>&1
    timeout /t 3 >nul
)

echo.
echo 2Ô∏è‚É£ Verificando Trading Chatbot API...
curl -s http://localhost:5001/health >nul 2>&1
if %errorlevel% equ 0 (
    echo ‚úÖ Trading Chatbot API j√° est√° rodando
) else (
    echo üöÄ Iniciando Trading Chatbot API...
    start /B python trading_chatbot_api.py > chatbot.log 2>&1
    timeout /t 2 >nul
)

echo.
echo 3Ô∏è‚É£ Verificando OpenWebUI...
curl -s http://localhost:8080 >nul 2>&1
if %errorlevel% equ 0 (
    echo ‚úÖ OpenWebUI j√° est√° rodando
) else (
    echo üöÄ Iniciando OpenWebUI...
    start /B open-webui serve --host 0.0.0.0 --port 8080 > openwebui.log 2>&1
    timeout /t 3 >nul
)

echo.
echo 4Ô∏è‚É£ Status dos servi√ßos:
echo üîó Ollama: http://localhost:11434
echo üîó Trading Chatbot API: http://localhost:5001
echo üîó OpenWebUI: http://localhost:8080
echo üîó Motor de Predi√ß√£o: http://localhost:5000

echo.
echo üéâ SISTEMA PRONTO!
echo üì± Acesse o chatbot em: http://localhost:8080
echo üìä Dashboard de predi√ß√£o em: http://localhost:5000/prediction/dashboard
echo.
echo Pressione qualquer tecla para continuar...
pause >nul
'''

        with open("start_trading_chatbot.bat", "w") as f:
            f.write(startup_bat)

        print("üìú Scripts criados:")
        print("üêß Linux/Mac: ./start_trading_chatbot.sh")
        print("ü™ü Windows: start_trading_chatbot.bat")

        return True

    def main(self):
        """Execu√ß√£o principal da instala√ß√£o"""
        print("TRADING CHATBOT IA INSTALLER")
        print("============================================")
        print("This script will install and configure:")
        print("* Ollama (AI engine)")
        print("* OpenWebUI (web interface)")
        print("* Trading Chatbot API (integration)")
        print()

        success_count = 0
        total_steps = 7

        # 1. Check Python
        print(f"Step 1/{total_steps}: Checking Python dependencies...")
        if self.check_python_dependencies():
            success_count += 1
        else:
            print("[FAIL] Critical failure - Python dependencies required")
            return False

        # 2. Install Ollama
        print(f"\nStep 2/{total_steps}: Installing Ollama...")
        if self.install_ollama():
            success_count += 1
        else:
            print("[WARN] Ollama may need manual installation")

        # 3. Start Ollama
        print(f"\nStep 3/{total_steps}: Starting Ollama service...")
        if self.start_ollama_service():
            # Test connection after a few seconds
            time.sleep(5)
            if self.test_ollama_connection():
                success_count += 1
            else:
                print("[WARN] Ollama started but no connection")
        else:
            print("[WARN] Ollama may need manual start")

        # 4. Download models
        print(f"\nStep 4/{total_steps}: Downloading AI models...")
        if self.pull_models():
            success_count += 1
        else:
            print("[WARN] Failed to download models")

        # 5. Install OpenWebUI
        print(f"\nStep 5/{total_steps}: Installing OpenWebUI...")
        if self.install_openwebui():
            success_count += 1
        else:
            print("[WARN] Failed to install OpenWebUI")

        # 6. Create API integration
        print(f"\nStep 6/{total_steps}: Creating integration API...")
        if self.create_trading_chatbot_api():
            success_count += 1
        else:
            print("[WARN] Failed to create API")

        # 7. Create startup scripts
        print(f"\nStep 7/{total_steps}: Creating startup scripts...")
        if self.create_startup_scripts():
            success_count += 1

        # 8. Test integrations (bonus step)
        print("\nTesting integrations...")
        if self.test_integration():
            print("[OK] System working!")
        else:
            print("[WARN] Some components may need adjustments")

        print("\n" + "="*50)
        print(f"INSTALLATION SUMMARY: {success_count}/{total_steps} components OK")
        print("="*50)

        if success_count >= 5:
            print("INSTALLATION MOSTLY SUCCESSFUL!")
            print("\\nüìã PR√ìXIMOS PASSOS:")
            print("1. Execute: ./start_trading_chatbot.sh (Linux/Mac) ou start_trading_chatbot.bat (Windows)")
            print("2. Acesse http://localhost:8080 no navegador")
            print("3. Teste perguntando: 'Ajude-me com an√°lise de trading no XAUUSD'")
            print("\\nüîó URLs importantes:")
            print("üì± Chatbot IA: http://localhost:8080")
            print("üìä Dashboard: http://localhost:5000/prediction/dashboard")
            print("ü§ñ API do Chatbot: http://localhost:5001")
            print("‚öôÔ∏è Ollama: http://localhost:11434")
        else:
            print("‚ö†Ô∏è PROBLEMAS DETECTADOS")
            print("Consulte os logs acima e reinstale componentes faltantes")

        print("\\nüí° Para suporte, verifique os arquivos de log gerados")
        print("="*50)

        return success_count >= 5

if __name__ == "__main__":
    installer = TradingChatbotInstaller()
    installer.main()
