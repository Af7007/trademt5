#!/usr/bin/env python3
"""
Sistema de InstalaÃ§Ã£o do Chatbot IA para Trading
Instala e configura: Ollama + OpenWebUI + IntegraÃ§Ã£o com Motor de PrediÃ§Ã£o
"""

import subprocess
import sys
import os
import time
import requests
import json
from pathlib import Path

class TradingChatbotInstaller:
    def __init__(self):
        self.base_dir = Path(__file__).parent
        self.ollama_url = "http://localhost:11434"
        self.openwebui_port = 8080
        self.openwebui_url = f"http://localhost:{self.openwebui_port}"

        # ConfiguraÃ§Ãµes dos modelos
        self.models_to_install = [
            "mistral",  # Modelo mais rÃ¡pida e eficiente
            "llama2:7b"  # Alternativa se mistral falhar
        ]

    def run_command(self, cmd, description="Executando comando", shell=False):
        """Executa comando do sistema com feedback"""
        print(f"[EXEC] {description}...")
        print(f"CMD: {cmd}")

        try:
            if shell:
                result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
            else:
                result = subprocess.run(cmd.split(), capture_output=True, text=True)

            if result.returncode == 0:
                print(f"[OK] {description}")
                if result.stdout:
                    print(f"Output: {result.stdout.strip()}")
                return True
            else:
                print(f"[FAIL] {description}")
                if result.stderr:
                    print(f"Error: {result.stderr.strip()}")
                return False

        except Exception as e:
            print(f"[ERROR] {description}: {str(e)}")
            return False

    def check_python_dependencies(self):
        """Verifica e instala dependÃªncias Python necessÃ¡rias"""
        required_packages = [
            "requests",
            "flask",
            "flask-cors"
        ]

        print("Checking Python dependencies...")

        for package in required_packages:
            try:
                __import__(package.replace("-", "_"))
                print(f"[OK] {package}")
            except ImportError:
                print(f"Installing {package}...")
                if not self.run_command(f"pip install {package}", f"Installing {package}"):
                    print(f"[FAIL] Could not install {package}")
                    return False

        return True

    def install_ollama(self):
        """Instala o Ollama"""
        print("Installing Ollama...")

        # Para Windows, baixa o installer
        if sys.platform == "win32":
            print("Windows platform detected")

            # Tenta instalar via curl
            if self.run_command("where curl", "Checking curl", shell=True):
                print("Downloading Ollama via curl...")
                ollama_install = 'curl -fsSL https://ollama.com/install.bat | powershell'
                return self.run_command(ollama_install, "Installing Ollama", shell=True)
            else:
                print("[FAIL] Ollama needs manual installation from: https://ollama.com/download")
                print("Run this script again after installation")
                return False
        else:
            print("Linux/Mac platform - installing via official script")
            # Para Linux/Mac
            return self.run_command('curl -fsSL https://ollama.com/install.sh | sh',
                                   "Installing Ollama on Linux/Mac", shell=True)

    def start_ollama_service(self):
        """Inicia o serviÃ§o Ollama"""
        print("Starting Ollama service...")

        # Tenta iniciar Ollama
        if sys.platform == "win32":
            # No Windows, precisa executar ollama serve
            try:
                # Tenta executar em background usando subprocess
                subprocess.Popen(["ollama", "serve"], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)
                time.sleep(3)  # Aguarda inicializaÃ§Ã£o
                print("[OK] Ollama started (background)")
                return True
            except:
                print("[FAIL] Could not start Ollama automatically")
                print("Run manually: ollama serve")
                return False
        else:
            # Linux/Mac pode usar systemctl ou iniciar diretamente
            return self.run_command("ollama serve", "Starting Ollama (will run in background)", shell=True)

    def pull_models(self):
        """Baixa modelos necessÃ¡rios"""
        print("Downloading AI models...")

        success = False
        for model in self.models_to_install:
            print(f"Downloading model: {model}")

            if self.run_command(f"ollama pull {model}", f"Downloading {model}"):
                success = True
                break  # Usa o primeiro modelo que conseguir baixar
            else:
                print(f"Warning: Failed to download {model}, trying next...")

        if not success:
            print("[FAIL] Could not download any models")
            print("Run manually: ollama pull mistral")
            return False

        return True

    def install_openwebui(self):
        """Instala o OpenWebUI"""
        print("Installing OpenWebUI...")

        try:
            # Instala via pip
            if self.run_command("pip install open-webui", "Installing OpenWebUI"):
                print("[OK] OpenWebUI installed via pip")

                # Cria script de inicializaÃ§Ã£o
                startup_script = '''#!/bin/bash
# Script para iniciar OpenWebUI
echo "Iniciando OpenWebUI..."
open-webui serve --host 0.0.0.0 --port 8080
'''

                with open("start_openwebui.sh", "w") as f:
                    f.write(startup_script)

                # TambÃ©m cria script Windows
                startup_bat = '''@echo off
echo Iniciando OpenWebUI...
open-webui serve --host 0.0.0.0 --port 8080
pause
'''

                with open("start_openwebui.bat", "w") as f:
                    f.write(startup_bat)

                print("ðŸ“œ Scripts de inicializaÃ§Ã£o criados:")
                print("ðŸ§ Linux/Mac: ./start_openwebui.sh")
                print("ðŸªŸ Windows: start_openwebui.bat")

                return True
            else:
                return False

        except Exception as e:
            print(f"âŒ Erro ao instalar OpenWebUI: {e}")
            return False

    def test_ollama_connection(self):
        """Testa conexÃ£o com Ollama"""
        print("ðŸ”— Testando conexÃ£o com Ollama...")

        try:
            response = requests.get(f"{self.ollama_url}/api/tags", timeout=5)
            if response.status_code == 200:
                models = response.json()
                print(f"âœ… Ollama conectado - Modelos disponÃ­veis: {len(models.get('models', []))}")

                for model in models.get('models', []):
                    print(f"  ðŸ“¦ {model.get('name', 'Unknown')}")
                return True
            else:
                print(f"âŒ Ollama respondeu com cÃ³digo {response.status_code}")
                return False

        except requests.exceptions.ConnectionError:
            print("âŒ NÃ£o foi possÃ­vel conectar ao Ollama")
            print("ðŸ’¡ Certifique-se que o Ollama estÃ¡ rodando: ollama serve")
            return False
        except Exception as e:
            print(f"âŒ Erro ao testar Ollama: {e}")
            return False

    def create_trading_chatbot_api(self):
        """Cria API de integraÃ§Ã£o com o chatbot IA"""
        print("ðŸ¤– Criando API de integraÃ§Ã£o do chatbot com motor de prediÃ§Ã£o...")

        # CÃ³digo da API de integraÃ§Ã£o
        chatbot_api_code = '''#!/usr/bin/env python3
"""
API de IntegraÃ§Ã£o: Chatbot IA com Motor de PrediÃ§Ã£o de Trading
Permite ao OpenWebUI fazer perguntas sobre o motor de prediÃ§Ã£o
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from flask import Flask, request, jsonify
from flask_cors import CORS
import requests
import json
import logging
from datetime import datetime

# Import motor de prediÃ§Ã£o
try:
    from prediction_engine import PredictionEngine
    from models import PredictionRequest
except ImportError as e:
    print(f"Erro ao importar motor de prediÃ§Ã£o: {e}")
    PredictionEngine = None

# ConfiguraÃ§Ã£o logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

app = Flask(__name__)
CORS(app)  # Permite requisiÃ§Ãµes do OpenWebUI

# URLs
OLLAMA_URL = "http://localhost:11434"
PREDICTION_API_URL = "http://localhost:5000"  # Motor de prediÃ§Ã£o existente

class TradingChatbotAssistant:
    """Assistente de trading que conecta IA com dados de prediÃ§Ã£o"""

    def __init__(self):
        self.prediction_engine = None
        if PredictionEngine:
            try:
                self.prediction_engine = PredictionEngine()
                logger.info("Motor de prediÃ§Ã£o conectado")
            except Exception as e:
                logger.error(f"Erro ao conectar motor de prediÃ§Ã£o: {e}")

    def query_ollama(self, prompt, model="mistral"):
        """Consulta modelo Ollama"""
        try:
            response = requests.post(
                f"{OLLAMA_URL}/api/generate",
                json={
                    "model": model,
                    "prompt": prompt,
                    "stream": False
                },
                timeout=30
            )

            if response.status_code == 200:
                return response.json()["response"]
            else:
                return f"Erro na API Ollama: {response.status_code}"

        except Exception as e:
            return f"Erro ao consultar Ollama: {str(e)}"

    def get_prediction_analysis(self, symbol, target_profit=None, balance=1000):
        """ObtÃ©m anÃ¡lise de prediÃ§Ã£o atual"""
        try:
            if not self.prediction_engine:
                return "Motor de prediÃ§Ã£o nÃ£o disponÃ­vel"

            # Cria requisiÃ§Ã£o
            request_data = PredictionRequest(
                symbol=symbol.upper(),
                target_profit=float(target_profit or 50.0),
                balance=float(balance)
            )

            # Gera prediÃ§Ã£o
            result = self.prediction_engine.predict(request_data)

            return {
                "estimated_operations": result.estimated_operations,
                "estimated_duration": result.estimated_duration_description,
                "success_probability": round(result.success_probability * 100, 1),
                "risk_level": result.risk_level,
                "backtest_results": result.backtest_results.to_dict() if result.backtest_results else "Dados histÃ³ricos nÃ£o disponÃ­veis"
            }

        except Exception as e:
            logger.error(f"Erro na anÃ¡lise de prediÃ§Ã£o: {e}")
            return f"Erro ao obter dados de prediÃ§Ã£o: {str(e)}"

    def process_trading_question(self, question, model="mistral"):
        """Processa pergunta sobre trading e gera resposta"""

        # Identifica tipo de pergunta
        question_lower = question.lower()

        # ReuniÃ£o de contextos baseada na pergunta
        context_parts = []

        # Sempre incluir dados atuais se perguntar sobre mercado ou prediÃ§Ãµes
        if any(keyword in question_lower for keyword in ["mercado", "preÃ§o", "anÃ¡lise", "prediÃ§Ã£o", "entr", "rsi", "macd"]):
            # Extrair sÃ­mbolos mencionados
            symbols_mentioned = []
            for symbol in ["xauusd", "btcusd", "eurusd", "gbpusd", "usdjpy"]:
                if symbol.lower() in question_lower:
                    symbols_mentioned.append(symbol.upper())

            if symbols_mentioned:
                context_parts.append(f"Dados atuais do mercado para: {', '.join(symbols_mentioned)}")
                for symbol in symbols_mentioned:
                    prediction_data = self.get_prediction_analysis(symbol)
                    if isinstance(prediction_data, dict):
                        context_parts.append(f"""
{symbol}:
- OperaÃ§Ãµes estimadas: {prediction_data['estimated_operations']}
- Tempo estimado: {prediction_data['estimated_duration']}
- Probabilidade de sucesso: {prediction_data['success_probability']}%
- NÃ­vel de risco: {prediction_data['risk_level']}
                        """.strip())

        # Prompt inteligente para Ollama baseado no contexto
        system_prompt = """VocÃª Ã© um assistente especialista em trading que combina anÃ¡lise tÃ©cnica e dados reais.

REGRAS IMPORTANTES:
- Seja preciso e conservador nas recomendaÃ§Ãµes
- Sempre mencione que a anÃ¡lise Ã© educacional
- Use dados fornecidos na pergunta
- Recomende sempre gerenciamento de risco
- NÃ£o promova trading irresponsÃ¡vel

RESPONDA EM PORTUGUÃŠS BRASILEIRO.
"""

        context_text = "CONTEXTO ATUAL:\\n" + "\\n".join(context_parts) if context_parts else "Sem dados especÃ­ficos disponÃ­veis no momento."

        full_prompt = f"{system_prompt}\\n\\n{context_text}\\n\\nPERGUNTA: {question}\\n\\nRESPOSTA:"

        # Consulta IA
        logger.info(f"Consultando IA sobre: {question[:50]}...")
        response = self.query_ollama(full_prompt, model)

        return response

# InstÃ¢ncia global
trading_assistant = TradingChatbotAssistant()

@app.route("/health")
def health_check():
    """Health check da API"""
    return jsonify({
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "services": {
            "ollama": test_ollama_connection(),
            "prediction_engine": trading_assistant.prediction_engine is not None
        }
    })

@app.route("/chat", methods=["POST"])
def chat_endpoint():
    """Endpoint principal para conversaÃ§Ã£o com chatbot"""
    try:
        data = request.json
        if not data or 'message' not in data:
            return jsonify({
                "error": "Campo 'message' obrigatÃ³rio",
                "example": {"message": "Qual a probabilidade para XAUUSD?", "model": "mistral"}
            }), 400

        question = data['message']
        model = data.get('model', 'mistral')

        logger.info(f"Nova pergunta: {question[:100]}...")

        # Processa pergunta
        response = trading_assistant.process_trading_question(question, model)

        return jsonify({
            "response": response,
            "timestamp": datetime.now().isoformat(),
            "model_used": model
        })

    except Exception as e:
        logger.error(f"Erro no chat endpoint: {e}")
        return jsonify({
            "error": f"Erro interno: {str(e)}",
            "timestamp": datetime.now().isoformat()
        }), 500

def test_ollama_connection():
    """Testa conexÃ£o com Ollama"""
    try:
        response = requests.get(f"{OLLAMA_URL}/api/tags", timeout=5)
        return response.status_code == 200
    except:
        return False

def main():
    print("ðŸ¤– Iniciando Trading Chatbot Assistant API...")
    print("ðŸ“¡ Endpoints:")
    print("  GET  /health  - Health check")
    print("  POST /chat    - Conversar com assistente (body: {'message': '...', 'model': 'mistral'})")
    print("ðŸš€ Servindo em http://localhost:5001")

    app.run(host='0.0.0.0', port=5001, debug=False)

if __name__ == "__main__":
    main()
'''

        # Salva arquivo API
        api_file = self.base_dir / "trading_chatbot_api.py"
        with open(api_file, "w", encoding="utf-8") as f:
            f.write(chatbot_api_code)

        print(f"ðŸ“ API criada: {api_file}")
        print("ðŸ”— Endpoint do chatbot: http://localhost:5001")

        return True

    def test_integration(self):
        """Testa integraÃ§Ãµes apÃ³s instalaÃ§Ã£o"""
        print("ðŸ§ª Testando integraÃ§Ãµes...")

        # Testa API do chatbot
        try:
            response = requests.get("http://localhost:5001/health", timeout=5)
            if response.status_code == 200:
                data = response.json()
                print("âœ… API do chatbot funcionando")
                print(f"   Ollama: {'âœ…' if data['services']['ollama'] else 'âŒ'}")
                print(f"   Motor de prediÃ§Ã£o: {'âœ…' if data['services']['prediction_engine'] else 'âŒ'}")

                # Testa chat
                test_question = "Qual a probabilidade de sucesso para XAUUSD?"
                chat_response = requests.post("http://localhost:5001/chat",
                    json={"message": test_question}, timeout=30)

                if chat_response.status_code == 200:
                    print("âœ… Chatbot funcionando")
                    print(f"   Resposta de teste: {chat_response.json()['response'][:100]}...")
                else:
                    print("âš ï¸ Chatbot iniciou mas sem resposta")

                return True
            else:
                print("âŒ API do chatbot nÃ£o responde")
                return False

        except Exception as e:
            print(f"âŒ Erro ao testar integraÃ§Ãµes: {e}")
            return False

    def create_startup_scripts(self):
        """Cria scripts de inicializaÃ§Ã£o do sistema completo"""
        print("ðŸ“œ Criando scripts de inicializaÃ§Ã£o...")

        # Script principal para iniciar tudo
        main_startup = '''#!/bin/bash
# Script completo para iniciar: Ollama + OpenWebUI + Trading Chatbot API
echo "=========================================="
echo "ðŸ¤– SISTEMA TRADING CHATBOT - INICIALIZANDO"
echo "=========================================="

echo ""
echo "1ï¸âƒ£ Iniciando Ollama..."
# Verifica se Ollama jÃ¡ estÃ¡ rodando
if curl -s http://localhost:11434/api/tags > /dev/null; then
    echo "âœ… Ollama jÃ¡ estÃ¡ rodando"
else
    echo "ðŸš€ Iniciando Ollama..."
    nohup ollama serve > ollama.log 2>&1 &
    sleep 3
fi

echo ""
echo "2ï¸âƒ£ Iniciando Trading Chatbot API..."
# Verifica se API jÃ¡ estÃ¡ rodando
if curl -s http://localhost:5001/health > /dev/null; then
    echo "âœ… Trading Chatbot API jÃ¡ estÃ¡ rodando"
else
    echo "ðŸš€ Iniciando Trading Chatbot API..."
    nohup python trading_chatbot_api.py > chatbot.log 2>&1 &
    sleep 2
fi

echo ""
echo "3ï¸âƒ£ Iniciando OpenWebUI..."
# Verifica se OpenWebUI jÃ¡ estÃ¡ rodando
if curl -s http://localhost:8080 > /dev/null; then
    echo "âœ… OpenWebUI jÃ¡ estÃ¡ rodando"
else
    echo "ðŸš€ Iniciando OpenWebUI..."
    nohup open-webui serve --host 0.0.0.0 --port 8080 > openwebui.log 2>&1 &
    sleep 3
fi

echo ""
echo "4ï¸âƒ£ Verificando status dos serviÃ§os..."
echo "ðŸ”— Ollama: http://localhost:11434"
echo "ðŸ”— Trading Chatbot API: http://localhost:5001"
echo "ðŸ”— OpenWebUI: http://localhost:8080"
echo "ðŸ”— Motor de PrediÃ§Ã£o: http://localhost:5000"

echo ""
echo "ðŸ§ª Testando conexÃµes..."
if curl -s http://localhost:11434/api/tags > /dev/null; then
    echo "âœ… Ollama OK"
else
    echo "âŒ Ollama FALHA"
fi

if curl -s http://localhost:5001/health > /dev/null; then
    echo "âœ… Chatbot API OK"
else
    echo "âŒ Chatbot API FALHA"
fi

if curl -s http://localhost:8080 > /dev/null; then
    echo "âœ… OpenWebUI OK"
else
    echo "âŒ OpenWebUI FALHA"
fi

echo ""
echo "ðŸŽ‰ SISTEMA PRONTO!"
echo "ðŸ“± Acesse o chatbot em: http://localhost:8080"
echo "ðŸ“Š Dashboard de prediÃ§Ã£o em: http://localhost:5000/prediction/dashboard"
echo ""
echo "ðŸ’¡ Digite: 'Me ajude com anÃ¡lise de trading no XAUUSD'"
echo "=========================================="
'''

        with open("start_trading_chatbot.sh", "w") as f:
            f.write(main_startup)

        # VersÃ£o Windows
        startup_bat = '''@echo off
echo ==========================================
echo ðŸ¤– SISTEMA TRADING CHATBOT - INICIALIZANDO
echo ==========================================
echo.

echo 1ï¸âƒ£ Verificando Ollama...
curl -s http://localhost:11434/api/tags >nul 2>&1
if %errorlevel% equ 0 (
    echo âœ… Ollama jÃ¡ estÃ¡ rodando
) else (
    echo ðŸš€ Iniciando Ollama...
    start /B ollama serve > ollama.log 2>&1
    timeout /t 3 >nul
)

echo.
echo 2ï¸âƒ£ Verificando Trading Chatbot API...
curl -s http://localhost:5001/health >nul 2>&1
if %errorlevel% equ 0 (
    echo âœ… Trading Chatbot API jÃ¡ estÃ¡ rodando
) else (
    echo ðŸš€ Iniciando Trading Chatbot API...
    start /B python trading_chatbot_api.py > chatbot.log 2>&1
    timeout /t 2 >nul
)

echo.
echo 3ï¸âƒ£ Verificando OpenWebUI...
curl -s http://localhost:8080 >nul 2>&1
if %errorlevel% equ 0 (
    echo âœ… OpenWebUI jÃ¡ estÃ¡ rodando
) else (
    echo ðŸš€ Iniciando OpenWebUI...
    start /B open-webui serve --host 0.0.0.0 --port 8080 > openwebui.log 2>&1
    timeout /t 3 >nul
)

echo.
echo 4ï¸âƒ£ Status dos serviÃ§os:
echo ðŸ”— Ollama: http://localhost:11434
echo ðŸ”— Trading Chatbot API: http://localhost:5001
echo ðŸ”— OpenWebUI: http://localhost:8080
echo ðŸ”— Motor de PrediÃ§Ã£o: http://localhost:5000

echo.
echo ðŸŽ‰ SISTEMA PRONTO!
echo ðŸ“± Acesse o chatbot em: http://localhost:8080
echo ðŸ“Š Dashboard de prediÃ§Ã£o em: http://localhost:5000/prediction/dashboard
echo.
echo Pressione qualquer tecla para continuar...
pause >nul
'''

        with open("start_trading_chatbot.bat", "w") as f:
            f.write(startup_bat)

        print("ðŸ“œ Scripts criados:")
        print("ðŸ§ Linux/Mac: ./start_trading_chatbot.sh")
        print("ðŸªŸ Windows: start_trading_chatbot.bat")

        return True

    def main(self):
        """ExecuÃ§Ã£o principal da instalaÃ§Ã£o"""
        print("TRADING CHATBOT IA INSTALLER")
        print("============================================")
        print("This script will install and configure:")
        print("* Ollama (AI engine)")
        print("* OpenWebUI (web interface)")
        print("* Trading Chatbot API (integration)")
        print()

        success_count = 0
        total_steps = 7

        # 1. Check Python
        print(f"Step 1/{total_steps}: Checking Python dependencies...")
        if self.check_python_dependencies():
            success_count += 1
        else:
            print("[FAIL] Critical failure - Python dependencies required")
            return False

        # 2. Install Ollama
        print(f"\nStep 2/{total_steps}: Installing Ollama...")
        if self.install_ollama():
            success_count += 1
        else:
            print("[WARN] Ollama may need manual installation")

        # 3. Start Ollama
        print(f"\nStep 3/{total_steps}: Starting Ollama service...")
        if self.start_ollama_service():
            # Test connection after a few seconds
            time.sleep(5)
            if self.test_ollama_connection():
                success_count += 1
            else:
                print("[WARN] Ollama started but no connection")
        else:
            print("[WARN] Ollama may need manual start")

        # 4. Download models
        print(f"\nStep 4/{total_steps}: Downloading AI models...")
        if self.pull_models():
            success_count += 1
        else:
            print("[WARN] Failed to download models")

        # 5. Install OpenWebUI
        print(f"\nStep 5/{total_steps}: Installing OpenWebUI...")
        if self.install_openwebui():
            success_count += 1
        else:
            print("[WARN] Failed to install OpenWebUI")

        # 6. Create API integration
        print(f"\nStep 6/{total_steps}: Creating integration API...")
        if self.create_trading_chatbot_api():
            success_count += 1
        else:
            print("[WARN] Failed to create API")

        # 7. Create startup scripts
        print(f"\nStep 7/{total_steps}: Creating startup scripts...")
        if self.create_startup_scripts():
            success_count += 1

        # 8. Test integrations (bonus step)
        print("\nTesting integrations...")
        if self.test_integration():
            print("[OK] System working!")
        else:
            print("[WARN] Some components may need adjustments")

        print("\n" + "="*50)
        print(f"INSTALLATION SUMMARY: {success_count}/{total_steps} components OK")
        print("="*50)

        if success_count >= 5:
            print("INSTALLATION MOSTLY SUCCESSFUL!")
            print("\\nðŸ“‹ PRÃ“XIMOS PASSOS:")
            print("1. Execute: ./start_trading_chatbot.sh (Linux/Mac) ou start_trading_chatbot.bat (Windows)")
            print("2. Acesse http://localhost:8080 no navegador")
            print("3. Teste perguntando: 'Ajude-me com anÃ¡lise de trading no XAUUSD'")
            print("\\nðŸ”— URLs importantes:")
            print("ðŸ“± Chatbot IA: http://localhost:8080")
            print("ðŸ“Š Dashboard: http://localhost:5000/prediction/dashboard")
            print("ðŸ¤– API do Chatbot: http://localhost:5001")
            print("âš™ï¸ Ollama: http://localhost:11434")
        else:
            print("âš ï¸ PROBLEMAS DETECTADOS")
            print("Consulte os logs acima e reinstale componentes faltantes")

        print("\\nðŸ’¡ Para suporte, verifique os arquivos de log gerados")
        print("="*50)

        return success_count >= 5

if __name__ == "__main__":
    installer = TradingChatbotInstaller()
    installer.main()
